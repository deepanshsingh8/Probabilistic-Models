{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "False\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# =============================== Task 1 ========================================\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Tue Oct  8 14:56:47 2019\n",
    "\n",
    "@author: Deepansh\n",
    "Zid: z5199370\n",
    "\"\"\"\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "graph = { \n",
    "        'BC':['Mass','AD','MC','SkinRetract','Nippledischarge','Metastasis'],\n",
    "        'Mass':['Size','Shape','Margin'],\n",
    "        'AD':['Fibrtissuedev'],\n",
    "        'MC':[],\n",
    "        'SkinRetract':[],\n",
    "        'Nippledischarge':[],\n",
    "        'Metastasis':['Lymphnodes'],\n",
    "        'Size':[],\n",
    "        'Shape':[],\n",
    "        'Margin':[],\n",
    "        'Fibrtissuedev':['Skinretract','Nippledischarge','Spiculation'],\n",
    "        'Lymphnodes':[],\n",
    "        'Breastdensity':['Mass'],\n",
    "        'Age':['BC'],\n",
    "        'Location':['BC'],\n",
    "        'Spiculation':['Margin']\n",
    "        }   \n",
    "\n",
    "#quiz Question\n",
    "g= {\n",
    "    'A':['C'],\n",
    "    'B':['C','D'],\n",
    "    'C':['F','E'],\n",
    "    'D':['E'],\n",
    "    'E':[],\n",
    "    'F':[]\n",
    "    }\n",
    "\n",
    "#question from slides\n",
    "g__ = {\n",
    "      'A':['T'],\n",
    "      'T':['P'],\n",
    "      'P':['X','D'],\n",
    "      'C':['P'],\n",
    "      'S':['B','C'],\n",
    "      'B':['D'],\n",
    "      'X':[],\n",
    "      'D':[]\n",
    "      }\n",
    "\n",
    "#random question\n",
    "g_ = {\n",
    "      'U': ['W'],\n",
    "      'V':['W','X','T'],\n",
    "      'W':['Y'],\n",
    "      'X':['Y'],\n",
    "      'T':['Z'],\n",
    "      'Z':[],\n",
    "      'Y':[]\n",
    "      }\n",
    "\n",
    "def d_seperation(G,X,Y,Z):\n",
    "    union = \" \".join(X) #create a single string for better searching, typically X U Y U Z\n",
    "    union +=\" \"+\" \".join(Y)\n",
    "    union +=\" \"+\" \".join(Z)\n",
    "    #using refine graph to apply the algorithm required by the assignment to get a refined graph\n",
    "    temp_dict=refine_graph(G,X,Y,Z,union) #this is a recursive function which removes all the leaf nodes and the node that is not required.\n",
    "    #creating a undirected graph after removing the nodes and the branches..\n",
    "    new_dict = {}\n",
    "    for key,value in temp_dict.items(): \n",
    "        for val in value: \n",
    "            if key in new_dict: #if key is there in  the dictionary, append the value, i.e. add an edge\n",
    "                new_dict[key].append(val)\n",
    "            else:\n",
    "                new_dict[key] = [val] #create a new key and add the vale, i.e. edge\n",
    "            \n",
    "            if val in new_dict:              \n",
    "                new_dict[val].append(key) #create the edge back so that its an undirected graph\n",
    "            else:\n",
    "                new_dict[val] = [key] #create the new key and add the edge.\n",
    "\n",
    "    #new_dict is an undirect graph in place of the original graph\n",
    "    path = []\n",
    "    #print(x_list,y_list)\n",
    "    for x in X:\n",
    "        for y in Y:\n",
    "            path += find_connection(new_dict,x,y) #recursive path finding algorithm\n",
    "    \n",
    "    #print(path)\n",
    "    if path==[]: #if no paths are found then that means that X and Y are d-seperated\n",
    "        return True\n",
    "    else: #otherwise not\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "def refine_graph(temp_dict,X,Y,Z,union):\n",
    "\n",
    "    #union = str(X)+'-'+str(Y)+'-'+str(Z) #create a single string for better searching, typically X U Y U Z\n",
    "    G=deepcopy(temp_dict) #copy the dictionary as the key values are being changed at each iteration\n",
    "    for key in G.keys():\n",
    "        if len(G[key])==0:\n",
    "            if key not in union: # this means node is not in X U Y U Z\n",
    "                temp_dict.pop(key,None) #remove key as it is a leaf nodek\n",
    "                for node in temp_dict.keys():\n",
    "                    try:\n",
    "                        temp_dict[node].remove(key) #remove the existence of the leaf node from the graph\n",
    "                    except ValueError:\n",
    "                        pass     \n",
    "    G=deepcopy(temp_dict)    #copy the dictionary again\n",
    "    for key in G.keys(): \n",
    "        if len(G[key])==0: #check and see if there are any new leaf nodes created due to removal of leaf nodes\n",
    "            if key not in union: #there are new leaf nodes and the node is not in X U Y U Z\n",
    "                temp_dict=refine_graph(temp_dict,X,Y,Z,union) #recursive call \n",
    "        else:\n",
    "            continue   \n",
    "    #now the second step of the algorithm, remove the outgoing branches of node that is in Z. \n",
    "    for key in temp_dict.keys():\n",
    "        if key in Z: #if the node is in Z, remove the branches\n",
    "            temp_dict[key] = [] #replace the list with empty list to remove any outgoing branches from the key\n",
    "    return temp_dict\n",
    "\n",
    "def find_connection(g, X, Y, path=[]):\n",
    "        path = path + [X] #add the paths together\n",
    "        if X == Y: #base function that if start node==end node\n",
    "            return path\n",
    "        if X not in g: #if Start node is not in the graph\n",
    "            return [] #return empty list\n",
    "        for node in g[X]: #for all nodes in the values\n",
    "            if node not in path:\n",
    "                newpath = find_connection(g, node, Y, path)\n",
    "                if newpath: return newpath\n",
    "        return [] #return empty list\n",
    "\n",
    "\n",
    "Test_1 = d_seperation(g, ['A'], ['D'], ['F'])\n",
    "print(Test_1) #false\n",
    "\n",
    "\n",
    "Test_2 = d_seperation(g, ['A'], ['D'], ['C'])\n",
    "print(Test_2) #false\n",
    "\n",
    "Test_3 = d_seperation(g_, ['U'], ['V'], ['W'])\n",
    "print(Test_3) #false\n",
    "\n",
    "Test_4 = d_seperation(g_, ['BC'], ['Margin'], ['AD'])\n",
    "print(Test_4) #True\n",
    "## reference : https://www.python.org/doc/essays/graphs/##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =============================== Task 2 ========================================\n",
    "\n",
    "#Get data from file, learn parameters\n",
    "from collections import OrderedDict as odict\n",
    "import pandas as pd\n",
    "from itertools import product, combinations\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "#==================== Code from Week 3 Tutorial ====================================\n",
    "\n",
    "\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [True, False, False]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "\n",
    "\n",
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='orgtbl'))\n",
    "\n",
    "def transposeGraph(G):\n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            if w in GT:\n",
    "                GT[w].append(v)\n",
    "            else:\n",
    "                GT[w] = [v]\n",
    "    return GT\n",
    "\n",
    "\n",
    "# From Week 2 Tutorial\n",
    "def estProbTable(data, var_name, parent_names, outcomeSpace):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `var_outcomes`, a tuple of possible outcomes for the conditiona varible and\n",
    "    `parent_names`, a tuple of columns to be used for the parents and\n",
    "    `parent_outcomes` a tuple of all possible parent outcomes \n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        cond_array = []\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            prob_table[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum() \n",
    "           \n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "#==================== End Tutorial Code ====================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Age   | Location    | BC       |         Pr |\n",
      "|-------+-------------+----------+------------|\n",
      "| 35-49 | LolwOutQuad | No       | 0.762726   |\n",
      "| 35-49 | LolwOutQuad | Invasive | 0.140394   |\n",
      "| 35-49 | LolwOutQuad | Insitu   | 0.0968801  |\n",
      "| 35-49 | UpOutQuad   | No       | 0.546699   |\n",
      "| 35-49 | UpOutQuad   | Invasive | 0.198873   |\n",
      "| 35-49 | UpOutQuad   | Insitu   | 0.254428   |\n",
      "| 35-49 | UpInQuad    | No       | 0.653481   |\n",
      "| 35-49 | UpInQuad    | Invasive | 0.160601   |\n",
      "| 35-49 | UpInQuad    | Insitu   | 0.185918   |\n",
      "| 35-49 | LowInQuad   | No       | 0.685275   |\n",
      "| 35-49 | LowInQuad   | Invasive | 0.141586   |\n",
      "| 35-49 | LowInQuad   | Insitu   | 0.173139   |\n",
      "| 50-74 | LolwOutQuad | No       | 0.549206   |\n",
      "| 50-74 | LolwOutQuad | Invasive | 0.30119    |\n",
      "| 50-74 | LolwOutQuad | Insitu   | 0.149603   |\n",
      "| 50-74 | UpOutQuad   | No       | 0.499797   |\n",
      "| 50-74 | UpOutQuad   | Invasive | 0.303289   |\n",
      "| 50-74 | UpOutQuad   | Insitu   | 0.196914   |\n",
      "| 50-74 | UpInQuad    | No       | 0.493585   |\n",
      "| 50-74 | UpInQuad    | Invasive | 0.345229   |\n",
      "| 50-74 | UpInQuad    | Insitu   | 0.161187   |\n",
      "| 50-74 | LowInQuad   | No       | 0.540348   |\n",
      "| 50-74 | LowInQuad   | Invasive | 0.354826   |\n",
      "| 50-74 | LowInQuad   | Insitu   | 0.104826   |\n",
      "| >75   | LolwOutQuad | No       | 0.641333   |\n",
      "| >75   | LolwOutQuad | Invasive | 0.201333   |\n",
      "| >75   | LolwOutQuad | Insitu   | 0.157333   |\n",
      "| >75   | UpOutQuad   | No       | 0.620448   |\n",
      "| >75   | UpOutQuad   | Invasive | 0.254902   |\n",
      "| >75   | UpOutQuad   | Insitu   | 0.12465    |\n",
      "| >75   | UpInQuad    | No       | 0.655172   |\n",
      "| >75   | UpInQuad    | Invasive | 0.201592   |\n",
      "| >75   | UpInQuad    | Insitu   | 0.143236   |\n",
      "| >75   | LowInQuad   | No       | 0.715447   |\n",
      "| >75   | LowInQuad   | Invasive | 0.185637   |\n",
      "| >75   | LowInQuad   | Insitu   | 0.098916   |\n",
      "| <35   | LolwOutQuad | No       | 0.986891   |\n",
      "| <35   | LolwOutQuad | Invasive | 0.00749064 |\n",
      "| <35   | LolwOutQuad | Insitu   | 0.00561798 |\n",
      "| <35   | UpOutQuad   | No       | 0.946535   |\n",
      "| <35   | UpOutQuad   | Invasive | 0.0237624  |\n",
      "| <35   | UpOutQuad   | Insitu   | 0.029703   |\n",
      "| <35   | UpInQuad    | No       | 0.946869   |\n",
      "| <35   | UpInQuad    | Invasive | 0.0322581  |\n",
      "| <35   | UpInQuad    | Insitu   | 0.0208729  |\n",
      "| <35   | LowInQuad   | No       | 0.966862   |\n",
      "| <35   | LowInQuad   | Invasive | 0.0155945  |\n",
      "| <35   | LowInQuad   | Insitu   | 0.0175439  |\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = {\n",
    "    'LymphNodes': [],\n",
    "    'Metastasis': ['LymphNodes'],\n",
    "    'BC': ['Metastasis','MC', 'SkinRetract', 'NippleDischarge', 'AD'],\n",
    "    'MC': [],\n",
    "    'Age': ['BC'],\n",
    "    'Location': ['BC'],\n",
    "    'BreastDensity': ['Mass'],\n",
    "    'Mass': ['Size', 'Shape', 'Margin'],\n",
    "    'Size': [],\n",
    "    'Shape': [],\n",
    "    'Margin': [],\n",
    "    'Spiculation': ['Margin'],\n",
    "    'FibrTissueDev': ['Spiculation', 'NippleDischarge', 'SkinRetract'],\n",
    "    'NippleDischarge': [],\n",
    "    'SkinRetract' : [],\n",
    "    'AD' : ['FibrTissueDev'],\n",
    "}\n",
    "\n",
    "graphT = transposeGraph(graph)\n",
    "\n",
    "\"\"\"\n",
    "Read the data, and return an outcomeSpace dictionary with\n",
    "all of the different nodes, and their domains\n",
    "\"\"\"\n",
    "def getOutcomeSpace(data):\n",
    "    \n",
    "    nodes = []\n",
    "    outcomes = []\n",
    "    \n",
    "    for x in data:\n",
    "        nodes.append(x)\n",
    "        count = 0\n",
    "        diffList = []\n",
    "        for val in data[x]:            \n",
    "            if val not in diffList:\n",
    "                count += 1\n",
    "                diffList.append(val)        \n",
    "        outcomes.append(diffList)\n",
    "        \n",
    "    outcomeSpace = {}\n",
    "    for i in range(len(nodes)):\n",
    "        outcomeSpace[nodes[i]] = tuple(outcomes[i])\n",
    "    \n",
    "   \n",
    "    return dict(outcomeSpace)\n",
    "\n",
    "def learn_bayes_net(graph, file, outcomeSpace, prob_tables):\n",
    "    \n",
    "\n",
    "    with open(file) as h:\n",
    "        data = pd.read_csv(h)\n",
    "\n",
    "    # possible outcomes, by variable\n",
    "    outcomeSpace = getOutcomeSpace(data)\n",
    "      \n",
    "\n",
    "    prob_tables = odict()\n",
    "    for node, parents in graphT.items():    \n",
    "        prob_tables[node] = estProbTable(         # Estimate the probability for a single table. 1 line\n",
    "            data,\n",
    "            node,\n",
    "            parents,\n",
    "            outcomeSpace)\n",
    "\n",
    "      \n",
    "    return outcomeSpace, prob_tables\n",
    "\n",
    "    \n",
    "prob_tables = []\n",
    "outcomeSpace = []\n",
    "\n",
    "outcomeSpace, prob_tables = learn_bayes_net(graph, 'bc_2.csv', outcomeSpace, prob_tables)\n",
    "printFactor(prob_tables['BC'])\n",
    "\n",
    "data = []\n",
    "with open('bc_2.csv') as h:\n",
    "        data = pd.read_csv(h)\n",
    "\n",
    "# =========================== End task 2 ====================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#=================== Task 3 ==========================\n",
    "\n",
    "import random\n",
    "\n",
    "# Recursively find child nodes such that nodes first in the ordering have no more unvisited children.\n",
    "def topologicalSortRec(G, v, ordering, visited):\n",
    "    \n",
    "    visited.append(v)\n",
    "    for child in G[v]:  \n",
    "        if child not in visited:\n",
    "            topologicalSortRec(G, child, ordering, visited)\n",
    "        \n",
    "    ordering.insert(0, v)\n",
    "\n",
    "#Find a topological ordering on the graph\n",
    "def topologicalSort(graph):\n",
    "    \n",
    "    ordering = []\n",
    "    visited = []\n",
    "    \n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            topologicalSortRec(graph, node, ordering, visited)\n",
    "            \n",
    "          \n",
    "    return ordering  # return the stack - ordering on the graph\n",
    "        \n",
    "#Returns a table with the subset of entries to consider for sampling - based on evidence\n",
    "def getSampleSpace(table, samples, node):\n",
    "    \n",
    "    keys = list(table['dom'])\n",
    "    \n",
    "    nodeIndex = keys.index(node)\n",
    "    \n",
    "    observed = []\n",
    "    indexes = {}\n",
    "    \n",
    "    for i in samples:\n",
    "        if i in keys:\n",
    "            observed.append(i)\n",
    "            indexes[keys.index(i)] = i\n",
    "        \n",
    "   \n",
    "    space = []\n",
    "    \n",
    "    listTable = list(table['table'].items())\n",
    "    \n",
    "    #Iterate through the table values, and take the ones with the correct data\n",
    "    for example in listTable:\n",
    "        nodes = list(example[0])\n",
    "        add = True\n",
    "        for i in indexes.keys():        \n",
    "            if nodes[i] != samples[indexes[i]]:\n",
    "                add = False\n",
    "                break\n",
    "        #Add the row from the table with the correctly observed data\n",
    "        if add == True:\n",
    "            space.append(example)\n",
    "            \n",
    "      \n",
    "    return space, nodeIndex\n",
    "    \n",
    "# Use a random number to generate a value from the outcomeSpace of var given the Sample Space probabilities\n",
    "def sampleValue(sampleSpace, nodeIndex):\n",
    "    \n",
    "    \n",
    "    rnd = random.random()\n",
    "    \n",
    "    lst = []\n",
    "    names = {}\n",
    "    for row in sampleSpace:\n",
    "        lst.append(row[1])\n",
    "        names[str(row[1])] = list(row[0])[nodeIndex]\n",
    "           \n",
    "    lst.sort()    \n",
    "\n",
    "    lst.insert(0, 0)\n",
    "   \n",
    "    #Split up the probabilities into 'regions' for the rnd to fall into    \n",
    "    regions = []\n",
    "    sumVal = 0\n",
    "    for i in range(1, len(lst)):\n",
    "        sumVal += lst[i - 1]\n",
    "        regions.append(lst[i] + sumVal)        \n",
    "    \n",
    "    lst.pop(0)\n",
    "        \n",
    "    for indx in range(len(regions)):\n",
    "        if rnd < regions[indx]:\n",
    "            chosen = indx\n",
    "            break\n",
    "   \n",
    "    chosenVal = names[str(lst[chosen])]     \n",
    "          \n",
    "    return chosenVal\n",
    "    \n",
    "#Sample from the graph in topological order\n",
    "def sample(graph, prob_tables):\n",
    "    \n",
    "    ordering = topologicalSort(graph)\n",
    "    samples = {}\n",
    " \n",
    "    for node in ordering:\n",
    "        sampleSpace, nodeIndex = getSampleSpace(prob_tables[node], samples, node)\n",
    "\n",
    "        val = sampleValue(sampleSpace, nodeIndex)\n",
    "        samples[node] = val     \n",
    "\n",
    "    return samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| BC       |       Pr |\n",
      "|----------+----------|\n",
      "| No       | 0.493585 |\n",
      "| Invasive | 0.345229 |\n",
      "| Insitu   | 0.161187 |\n"
     ]
    }
   ],
   "source": [
    "# ================== Code from wk  3 tutorial ======================\n",
    "def normalize(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be normalized.\n",
    "    \n",
    "    Returns a new factor f' as a copy of f with entries that sum up to 1\n",
    "    \"\"\" \n",
    "    table = list()\n",
    "    sum = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "    for k, p in f['table'].items():\n",
    "        table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}\n",
    "\n",
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "    \n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "\n",
    "    return factor['table'][entry]     # insert your code here, 1 line    \n",
    "\n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "\n",
    "\n",
    "def p_joint(outcomeSpace, cond_tables, nodeList):\n",
    "            \n",
    "   \n",
    "    if len(nodeList) < 2:\n",
    "        return cond_tables\n",
    "    \n",
    "    \"\"\"\n",
    "    argument \n",
    "    `outcomeSpace`, dictionary with domain of each variable\n",
    "    `cond_tables`, conditional probability distributions estimated from data\n",
    "    \n",
    "    Returns a new factor with full joint distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    p = join(cond_tables[nodeList[0]],  cond_tables[nodeList[1]], outcomeSpace)\n",
    "    for n in range(2, len(nodeList)):\n",
    "        p = join(p, cond_tables[nodeList[n]], outcomeSpace)\n",
    "   \n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "  \n",
    "       \n",
    "    #########################\n",
    "    # Insert your code here #\n",
    "    #########################\n",
    "    new_dom.remove(var)   \n",
    "    # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "            \n",
    "\n",
    "            #########################\n",
    "            # Insert your code here #\n",
    "            #########################\n",
    "            \n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}\n",
    "\n",
    "\n",
    "def evidence(var, e, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `var`, a valid variable identifier.\n",
    "    `e`, the observed value for var.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns dictionary with a copy of outcomeSpace with var = e\n",
    "    \"\"\"    \n",
    "    newOutcomeSpace = outcomeSpace.copy()      # Make a copy of outcomeSpace with a copy to method copy(). 1 line\n",
    "    newOutcomeSpace[var] = (e,)                # Replace the domain of variable var with a tuple with a single element e. 1 line\n",
    "    return newOutcomeSpace\n",
    "\n",
    "def query(p, outcomeSpace, q_vars, q_evi):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `p`, probability table to query.\n",
    "    `outcomeSpace`, dictionary will variable domains\n",
    "    `q_vars`, list of variables in query head\n",
    "    `q_evi`, dictionary of evidence in the form of variables names and values\n",
    "    \n",
    "    Returns a new factor NORMALIZED factor will all hidden variables eliminated as evidence set as in q_evi\n",
    "    \"\"\"     \n",
    "    \n",
    "    # Let's make a copy of these structures, since we will reuse the variable names\n",
    "    pm = p.copy()\n",
    "    outSpace = outcomeSpace.copy()\n",
    "    \n",
    "    # First, we set the evidence \n",
    "    for var_evi, e in q_evi.items():\n",
    "        outSpace = evidence(var_evi, e, outSpace)\n",
    "    \n",
    "    # Second, we eliminate hidden variables NOT in the query\n",
    "    for var in outSpace:\n",
    "        if not var in q_vars:            \n",
    "            pm = marginalize(pm, var, outSpace)\n",
    "            \n",
    "    return normalize(pm)\n",
    "\n",
    "#=================== End tutorial code ===================================================\n",
    "\n",
    "#Calculate full joint distribution for the queries\n",
    "queryNodes = list(outcomeSpace.keys())\n",
    "p = p_joint(outcomeSpace, prob_tables, queryNodes)\n",
    "\n",
    "#Test Query\n",
    "printFactor(query(p, outcomeSpace,['BC'], {'Age':'50-74', 'Location':'UpInQuad'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BreastDensity': ('high', 'medium', 'low'), 'Location': ('LolwOutQuad', 'UpOutQuad', 'UpInQuad', 'LowInQuad'), 'Age': ('35-49', '50-74', '>75', '<35'), 'BC': ('No', 'Invasive', 'Insitu'), 'Mass': ('No', 'Benign', 'Malign'), 'AD': ('No', 'Yes'), 'Metastasis': ('no', 'yes'), 'MC': ('No', 'Yes'), 'Size': ('<1cm', '1-3cm', '>3cm'), 'Shape': ('Other', 'Oval', 'Round', 'Irregular'), 'FibrTissueDev': ('No', 'Yes'), 'LymphNodes': ('no', 'yes'), 'SkinRetract': ('No', 'Yes'), 'NippleDischarge': ('No', 'Yes'), 'Spiculation': ('No', 'Yes'), 'Margin': ('Well-defined', 'Ill-defined')}\n"
     ]
    }
   ],
   "source": [
    "#Querying from a generated sample\n",
    "def querySample(samples, var, var_evi, outcomeSpace, probTables):\n",
    "    \n",
    "    if len(samples) == 0:\n",
    "        return\n",
    "    \n",
    "    if len(var) == 0:\n",
    "        return\n",
    "    \n",
    "    #Get the structure for the frequencies table    \n",
    "    parents = [a for a in var]\n",
    "    parents.pop(0)\n",
    "    frequencies = estProbTable(         # Estimate the probability for a single table. 1 line\n",
    "            data,\n",
    "            var[0],\n",
    "            parents,\n",
    "            outcomeSpace)\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    #Initalise frequency dictionary\n",
    "    for key, it in frequencies['table'].items():\n",
    "        frequencies['table'][key] = 0\n",
    "    \n",
    "    for s in samples:\n",
    "        discard = False\n",
    "        for key, it in s.items():\n",
    "            if key in var_evi:\n",
    "                if var_evi[key] != it:                   \n",
    "                    discard = True\n",
    "                    break\n",
    "       \n",
    "                \n",
    "        #Discard sample if disagrees with evidence          \n",
    "        if discard == True:\n",
    "            continue\n",
    "        \n",
    "        count += 1\n",
    "        vals = []\n",
    "        for v in frequencies['dom']:\n",
    "            vals.append(s[v])\n",
    "        \n",
    "        vals = tuple(vals)\n",
    "        frequencies['table'][vals] += 1\n",
    "            \n",
    "    for key, it in frequencies['table'].items():\n",
    "        if count > 0:            \n",
    "            frequencies['table'][key] /= count\n",
    "        \n",
    "    return frequencies\n",
    "\n",
    "\n",
    "generatedSamples = []\n",
    "\n",
    "import math\n",
    "def getAnalysis(probsSample, probsBayes):\n",
    "    \n",
    "    sampledList = []\n",
    "    bayesList = []\n",
    "    \n",
    "    s = []   \n",
    "\n",
    "    mseSum = 0\n",
    "    \n",
    "    \n",
    "    for samp in probsSample:\n",
    "        for key, it in samp['table'].items():\n",
    "            sampledList.append(samp['table'][key])\n",
    "            \n",
    "        \n",
    "    for bayes in probsBayes:\n",
    "        for key, it in bayes['table'].items():\n",
    "            bayesList.append(bayes['table'][key])\n",
    "    \n",
    "    cnt = 0\n",
    "    #Calculate Mean Squared Error\n",
    "    for i in range(len(bayesList)):\n",
    "        er = (bayesList[i] - sampledList[i])\n",
    "        er = er * er\n",
    "        mseSum += er\n",
    "        cnt += 1\n",
    "    if cnt > 0:\n",
    "        mseSum /= cnt\n",
    "        \n",
    "    mseSum = math.sqrt(mseSum)\n",
    "   \n",
    "    #Plot probabilities\n",
    "    %matplotlib notebook\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    x = [a for a in range(len(sampledList))]\n",
    "    \n",
    "    plt.plot(x,sampledList)\n",
    "    plt.plot(x,bayesList)\n",
    "    plt.ylabel('Probability')\n",
    "    plt.xlabel('Query Points')\n",
    "    \n",
    "    plt.legend(['SampledProbs', 'BayesNet Probs'], loc='upper left')\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "        \n",
    "    print(\"Mean Sqaured Error - \" + str(mseSum))  \n",
    "           \n",
    "    return mseSum\n",
    "\n",
    "# Generate 1000 Samples from forward sampling on the network\n",
    "for x in range(1000):\n",
    "    s = sample(graph, prob_tables)\n",
    "    generatedSamples.append(s)\n",
    "    \n",
    "print(outcomeSpace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\ANACONDA\\lib\\site-packages\\ipykernel_launcher.py:98: RuntimeWarning: invalid value encountered in long_scalars\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-4e77d09634b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;31m#Graph the probabilities from the sampled and Bayes net - calculate MSE\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m \u001b[0mgetAnalysis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprobsSampled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprobsBayes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-6-681b01192b12>\u001b[0m in \u001b[0;36mgetAnalysis\u001b[1;34m(probsSample, probsBayes)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m     \u001b[1;31m#Plot probabilities\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'notebook'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2312\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'local_ns'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getframe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_locals\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2313\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2314\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2315\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2316\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<D:\\ANACONDA\\lib\\site-packages\\decorator.py:decorator-gen-109>\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\IPython\\core\\magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    185\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\IPython\\core\\magics\\pylab.py\u001b[0m in \u001b[0;36mmatplotlib\u001b[1;34m(self, line)\u001b[0m\n\u001b[0;32m     97\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Available matplotlib backends: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbackends_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m             \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menable_matplotlib\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_show_matplotlib_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\IPython\\core\\interactiveshell.py\u001b[0m in \u001b[0;36menable_matplotlib\u001b[1;34m(self, gui)\u001b[0m\n\u001b[0;32m   3400\u001b[0m         \"\"\"\n\u001b[0;32m   3401\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpylabtools\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3402\u001b[1;33m         \u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_gui_and_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgui\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpylab_gui_select\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3403\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3404\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\ANACONDA\\lib\\site-packages\\IPython\\core\\pylabtools.py\u001b[0m in \u001b[0;36mfind_gui_and_backend\u001b[1;34m(gui, gui_select)\u001b[0m\n\u001b[0;32m    274\u001b[0m     \"\"\"\n\u001b[0;32m    275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 276\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mgui\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;34m'auto'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "# ====== General Accuracy Comparison =======\n",
    "\n",
    "queryVars = [['BC'], ['BC'], ['BC'], ['LymphNodes'],  ['LymphNodes'],  ['LymphNodes', 'BC'], \\\n",
    "                   ['LymphNodes', 'BC'], ['LymphNodes', 'BC', 'Mass'], ['SkinRetract'], ['NippleDischarge']]\n",
    "\n",
    "queryEvidence = [{}, {'Age':'50-74'}, {'Age':'50-74', 'Location':'UpInQuad'},{}, {'Metastasis': 'no'}, \\\n",
    "                {'Metastasis': 'no', 'Location':'UpInQuad'}, {'Metastasis' :'no', 'Location': 'UpInQuad'}, \\\n",
    "                {'Age' : '50-74', 'BreastDensity': 'medium'}, {'BC' : 'No'}, {'FibrTissueDev': 'No'}]\n",
    "\n",
    "\n",
    "#Get sample queries\n",
    "probsSampled = []\n",
    "for i in range(len(queryVars)):\n",
    "    var = queryVars[i]\n",
    "    evi = queryEvidence[i]\n",
    "    probsSampled.append(querySample(generatedSamples, var, evi, outcomeSpace, prob_tables))\n",
    "\n",
    "#Get bayesNet queries\n",
    "probsBayes = []\n",
    "for i in range(len(queryVars)):\n",
    "    var = queryVars[i]\n",
    "    evi = queryEvidence[i]\n",
    "    probsBayes.append(query(p, outcomeSpace,var, evi))\n",
    "\n",
    "#Graph the probabilities from the sampled and Bayes net - calculate MSE\n",
    "getAnalysis(probsSampled, probsBayes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ========== Increasing Evidence Accuracy Comparison ==============\n",
    "\n",
    "queryVars = [['LymphNodes', 'BC', 'Mass', 'SkinRetract', 'Margin'] for x in range(9)]\n",
    "\n",
    "queryEvidence = [{}, {'Age':'50-74'}, {'Age':'50-74', 'Location':'UpInQuad'}, \\\n",
    "                {'Age':'50-74', 'Location':'UpInQuad'}, \\\n",
    "                {'Age':'50-74', 'Location':'UpInQuad', 'Metastasis': 'no'}, \\\n",
    "                {'Age':'50-74', 'Location':'UpInQuad', 'Metastasis': 'no'}, \\\n",
    "                {'Age':'50-74', 'Location':'UpInQuad', 'Metastasis': 'no', 'BreastDensity': 'medium'}, \\\n",
    "                {'Age':'50-74', 'Location':'UpInQuad', 'Metastasis': 'no', 'BreastDensity': 'medium', 'FibrTissueDev':'No'}, \\\n",
    "                {'Age':'50-74', 'Location':'UpInQuad', 'Metastasis': 'no', 'BreastDensity': 'medium', 'FibrTissueDev':'No', 'Spiculation': 'No' }]\n",
    "\n",
    "\n",
    "#Get sample queries\n",
    "probsSampled = []\n",
    "for i in range(len(queryVars)):\n",
    "    var = queryVars[i]\n",
    "    evi = queryEvidence[i]\n",
    "    probsSampled.append(querySample(generatedSamples, var, evi, outcomeSpace, prob_tables))\n",
    "    \n",
    "\n",
    "\n",
    "#Get bayesNet queries\n",
    "probsBayes = []\n",
    "for i in range(len(queryVars)):\n",
    "    var = queryVars[i]\n",
    "    evi = queryEvidence[i]\n",
    "    probsBayes.append(query(p, outcomeSpace,var, evi))\n",
    "\n",
    "\n",
    "#Graph the probabilities from the sampled and Bayes net - calculate MSE\n",
    "getAnalysis(probsSampled, probsBayes)\n",
    "#================================= End task 3 ==================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================Task 4 ML Classifier =======================================\n",
    "\n",
    "'''\n",
    "This is the task 4  which is done with ML classifiers (KNN, RFC)\n",
    "Comments to be updated later\n",
    "'''\n",
    "\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "# Necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import model_selection\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "input_file = 'resources/bc_2.csv'\n",
    "\n",
    "with open(input_file) as f:\n",
    "    data = pd.read_csv(f)\n",
    "\n",
    "print(data.head())\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "data_encode = data.copy()\n",
    "for col in data_encode.columns:\n",
    "    data_encode[col] = le.fit_transform(data_encode[col])\n",
    "\n",
    "print(data_encode.head())\n",
    "print(data.head())\n",
    "\n",
    "Y = data_encode[\"BC\"]\n",
    "X = data_encode.drop([\"BC\"], axis=1)\n",
    "print(X.shape)\n",
    "\n",
    "seed = 10\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=0.2, random_state=seed)\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "print(X_train.shape)\n",
    "\n",
    "# K Nearest Neighbor\n",
    "count = 0\n",
    "nob = 15\n",
    "neighbors = range(1, nob)\n",
    "for neighbor in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors=neighbor)\n",
    "    knn.fit(X_train, Y_train)\n",
    "    knn_score = round(knn.score(X_train, Y_train) * 100, 2)\n",
    "    print('KNN Score for number of neighbors {} is {}: \\n'.format(neighbor, knn_score))\n",
    "\n",
    "    # Predict Output\n",
    "    predicted = knn.predict(X_test)\n",
    "\n",
    "    # Accuracy Score of KNN\n",
    "    if neighbor > 10:\n",
    "        a = accuracy_score(Y_test, predicted)\n",
    "        if neighbor is 18:\n",
    "            print(\"Classification Report :\")\n",
    "            print(classification_report(Y_test, predicted))\n",
    "            conf2 = confusion_matrix(Y_test, predicted)\n",
    "            print(conf2)\n",
    "        count = count + a\n",
    "        print('Accuracy Score for KNN with number of neighbors {} is {}: \\n'.format(neighbor, a))\n",
    "    else:\n",
    "        print('Accuracy Score for KNN with number of neighbors {} is {}: \\n'.format(neighbor,\n",
    "                                                                                    accuracy_score(Y_test, predicted)))\n",
    "\n",
    "print('The average accuracy is {}'.format((count / (nob - 10))))\n",
    "\n",
    "\n",
    "# Random Forest\n",
    "rf = RandomForestClassifier(max_depth=5, n_estimators=100, random_state=0)\n",
    "rf.fit(X_train, Y_train)\n",
    "print(\"Accuracy of Random Forest Classifier on training set: {:.3f}\".format(rf.score(X_train, Y_train)))\n",
    "\n",
    "predictions_rf = rf.predict(X_test)\n",
    "\n",
    "# Accuracy Score of LG\n",
    "print(\"Accuracy Score on prediction is:\")\n",
    "print(accuracy_score(Y_test, predictions_rf))\n",
    "# Classification Report\n",
    "print(\"Classification Report on RFC :\")\n",
    "print(classification_report(Y_test, predictions_rf))\n",
    "conf5 = confusion_matrix(Y_test, predictions_rf)\n",
    "print(conf5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================Task 4 Bayesian Network =======================================\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.8 #Divding the train to 80 percent\n",
    "train_data = data.loc[0:data.shape[0]*train_split-1, :]\n",
    "test_data = data.loc[data.shape[0]*train_split:, :]\n",
    "print(train_data.shape)\n",
    "print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv = train_data.to_csv('train.csv', index = None, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomeSpace, train_prob_tables = learn_bayes_net(graphT, 'train.csv', outcomeSpace, prob_tables)\n",
    "test_p = p_joint(outcomeSpace, train_prob_tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printFactor(train_prob_tables['BC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = test_data[\"BC\"]\n",
    "test_X = test_data.drop([\"BC\"], axis=1)\n",
    "test_evidence = odict()\n",
    "print(test_X.shape)\n",
    "y = test_X.iloc[0:1]\n",
    "test_column = list(test_X.columns)\n",
    "print(len(test_column))\n",
    "print(y.shape)\n",
    "for i in range(y.shape[0]):\n",
    "    for j in range(y.shape[1]):\n",
    "        print(j)\n",
    "        test_evidence[test_column[j]] = test_data.iloc[i][test_column[j]]\n",
    "    printFactor(query(train_prob_tables, outcomeSpace, 'BC', test_evidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data_encode[\"BC\"]\n",
    "test_X = data_encode.drop([\"BC\"], axis=1)\n",
    "test_evidence = odict()\n",
    "print(test_X.shape)\n",
    "test_X.iloc[0]\n",
    "test_column = list(test_X.columns)\n",
    "print(len(test_column))\n",
    "for i in range(test_data.shape[0]):\n",
    "    for j in range(test_data.shape[1]):\n",
    "        test_evidence[test_column[j]] = test_data.iloc[i][test_column[j]]\n",
    "    printFactor(query(train_prob_tables, outcomeSpace, 'BC', test_evidence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
