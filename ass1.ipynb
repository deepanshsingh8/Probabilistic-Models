{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "#Sample graph representation\n",
    "\"\"\"\n",
    "graph = {\n",
    "    1: [2,5],\n",
    "    2: [3,5],\n",
    "    3: [6, 7],\n",
    "    4: [1,5],\n",
    "    5: [6],\n",
    "    6: [2],\n",
    "    7: [],\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "graph = {\n",
    "    'L': ['R'],\n",
    "    'R': ['D','T'],\n",
    "    'B': ['T'],\n",
    "    'D': [],\n",
    "    'T': ['Z'],\n",
    "    'Z': [],\n",
    "}\n",
    "\n",
    "def disconnected(G, X, Y):\n",
    "   #bfs path search for some node in X to some node in Y\n",
    "\n",
    "    visited = []\n",
    "    stack = []\n",
    "    stack.append(X[0])\n",
    "    while len(stack) != 0:\n",
    "        node = stack.pop(0)\n",
    "        if node == Y[0]:\n",
    "            return False\n",
    "        visited.append(node)\n",
    "        for x in G[node]:\n",
    "            if x not in visited:\n",
    "                stack.append(x)\n",
    "            \n",
    "    return True\n",
    "            \n",
    "                \n",
    "\n",
    "def d_seperation(G, X, Y, Z):\n",
    "    \n",
    "    #pruning\n",
    "    # 1. Remove leaf nodes not in X + Y + Z\n",
    "    union = X + Y + Z\n",
    "    for leaf in G.copy():\n",
    "        if len(G[leaf]) == 0 and leaf not in union:\n",
    "            del G[leaf]\n",
    "            # Delete incoming edges to previously removed leaf\n",
    "            for node in G.keys():\n",
    "                try:\n",
    "                    G[node].remove(leaf)\n",
    "                except ValueError:\n",
    "                    pass  #leaf not in that node\n",
    "                \n",
    "    #2. remove outgoing edges from Z nodes           \n",
    "    for node in Z:\n",
    "        G[node] = []\n",
    "    \n",
    "              \n",
    "    return disconnected(G,X,Y)\n",
    "\n",
    "a = d_seperation(graph, ['L'], ['B'], ['T'])\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data from file, learn parameters\n",
    "from collections import OrderedDict as odict\n",
    "import pandas as pd\n",
    "from itertools import product, combinations\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "#================= Code from Week 3 Tutorial ====================================\n",
    "\n",
    "\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [True, False, False]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "\n",
    "\n",
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='orgtbl'))\n",
    "\n",
    "def transposeGraph(G):\n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            if w in GT:\n",
    "                GT[w].append(v)\n",
    "            else:\n",
    "                GT[w] = [v]\n",
    "    return GT\n",
    "\n",
    "\n",
    "# From Week 2 Tutorial\n",
    "def estProbTable(data, var_name, parent_names, outcomeSpace):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `var_outcomes`, a tuple of possible outcomes for the conditiona varible and\n",
    "    `parent_names`, a tuple of columns to be used for the parents and\n",
    "    `parent_outcomes` a tuple of all possible parent outcomes \n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        cond_array = []\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            prob_table[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum() \n",
    "           \n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "#==========================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated P(Location)=\n",
      "| Mass   | Shape     |        Pr |\n",
      "|--------+-----------+-----------|\n",
      "| No     | Other     | 1         |\n",
      "| No     | Oval      | 0         |\n",
      "| No     | Round     | 0         |\n",
      "| No     | Irregular | 0         |\n",
      "| Benign | Other     | 0.0553152 |\n",
      "| Benign | Oval      | 0.239184  |\n",
      "| Benign | Round     | 0.652967  |\n",
      "| Benign | Irregular | 0.052534  |\n",
      "| Malign | Other     | 0         |\n",
      "| Malign | Oval      | 0.153493  |\n",
      "| Malign | Round     | 0.104907  |\n",
      "| Malign | Irregular | 0.7416    |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = {\n",
    "    'LymphNodes': [],\n",
    "    'Metastasis': ['LymphNodes'],\n",
    "    'BC': ['Metastasis','MC', 'SkinRetract', 'NippleDischarge', 'AD'],\n",
    "    'MC': [],\n",
    "    'Age': ['BC'],\n",
    "    'Location': ['BC'],\n",
    "    'BreastDensity': ['Mass'],\n",
    "    'Mass': ['Size', 'Shape', 'Margin'],\n",
    "    'Size': [],\n",
    "    'Shape': [],\n",
    "    'Margin': [],\n",
    "    'Spiculation': ['Margin'],\n",
    "    'FibrTissueDev': ['Spiculation', 'NippleDischarge', 'SkinRetract'],\n",
    "    'NippleDischarge': [],\n",
    "    'SkinRetract' : [],\n",
    "    'AD' : ['FibrTissueDev'],\n",
    "}\n",
    "\n",
    "graphT = transposeGraph(graph)\n",
    "\n",
    "\"\"\"\n",
    "Read the data, and return an outcomeSpace dictionary with\n",
    "all of the different nodes, and their domains\n",
    "\"\"\"\n",
    "def getOutcomeSpace(data):\n",
    "    \n",
    "    nodes = []\n",
    "    outcomes = []\n",
    "    \n",
    "    for x in data:\n",
    "        nodes.append(x)\n",
    "        count = 0\n",
    "        diffList = []\n",
    "        for val in data[x]:            \n",
    "            if val not in diffList:\n",
    "                count += 1\n",
    "                diffList.append(val)        \n",
    "        outcomes.append(diffList)\n",
    "        \n",
    "    outcomeSpace = {}\n",
    "    for i in range(len(nodes)):\n",
    "        outcomeSpace[nodes[i]] = tuple(outcomes[i])\n",
    "    \n",
    "   \n",
    "    return dict(outcomeSpace)\n",
    "\n",
    "def learn_bayes_net(graph, file, outcomeSpace, prob_tables):\n",
    "    \n",
    "\n",
    "    with open(file) as h:\n",
    "        data = pd.read_csv(h)\n",
    "\n",
    "    # possible outcomes, by variable\n",
    "    outcomeSpace = getOutcomeSpace(data)\n",
    "      \n",
    "\n",
    "    prob_tables = odict()\n",
    "    for node, parents in graphT.items():    \n",
    "        prob_tables[node] = estProbTable(         # Estimate the probability for a single table. 1 line\n",
    "            data,\n",
    "            node,\n",
    "            parents,\n",
    "            outcomeSpace)\n",
    "\n",
    "    ##############################\n",
    "    # Test code\n",
    "    ##############################\n",
    "    print('estimated P(Location)=')\n",
    "    printFactor(prob_tables['Shape'])\n",
    "    print()\n",
    "    \n",
    "  \n",
    "    return outcomeSpace, prob_tables\n",
    "\n",
    "    \n",
    "prob_tables = []\n",
    "outcomeSpace = []\n",
    "\n",
    "outcomeSpace, prob_tables = learn_bayes_net(graph, 'bc 2.csv', outcomeSpace, prob_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('high',)\n",
      "('medium',)\n",
      "('low',)\n",
      "[0, 0.19945, 0.30145, 0.4991, 1]\n",
      "('high', 'No')\n",
      "('high', 'Benign')\n",
      "('high', 'Malign')\n",
      "('medium', 'No')\n",
      "('medium', 'Benign')\n",
      "('medium', 'Malign')\n",
      "('low', 'No')\n",
      "('low', 'Benign')\n",
      "('low', 'Malign')\n",
      "[0, 0.1413888192529456, 0.16259266680024043, 0.17172223614941087, 0.17399237021064853, 0.19895812462432377, 0.24315806933156411, 0.5828495604577874, 0.6384492085754357, 0.6868889445976435, 1]\n",
      "('No', 'Other')\n",
      "('No', 'Oval')\n",
      "('No', 'Round')\n",
      "('No', 'Irregular')\n",
      "('Benign', 'Other')\n",
      "('Benign', 'Oval')\n",
      "('Benign', 'Round')\n",
      "('Benign', 'Irregular')\n",
      "('Malign', 'Other')\n",
      "('Malign', 'Oval')\n",
      "('Malign', 'Round')\n",
      "('Malign', 'Irregular')\n",
      "[0, 0.0, 0.0, 0.0, 0.0, 0.05253399258343634, 0.055315203955500616, 0.10490693739424704, 0.15349286922890984, 0.2391841779975278, 0.6529666254635352, 0.7416001933768431, 1.0, 1]\n",
      "('No', '<1cm')\n",
      "('No', '1-3cm')\n",
      "('No', '>3cm')\n",
      "('Benign', '<1cm')\n",
      "('Benign', '1-3cm')\n",
      "('Benign', '>3cm')\n",
      "('Malign', '<1cm')\n",
      "('Malign', '1-3cm')\n",
      "('Malign', '>3cm')\n",
      "[0, 0.0, 0.0, 0.10352286773794808, 0.15228426395939088, 0.2567985166872682, 0.2871646120377085, 0.5605511240029006, 0.6396786155747837, 1.0, 1]\n",
      "('LolwOutQuad',)\n",
      "('UpOutQuad',)\n",
      "('UpInQuad',)\n",
      "('LowInQuad',)\n",
      "[0, 0.2462, 0.25075, 0.2511, 0.25195, 1]\n",
      "('35-49',)\n",
      "('50-74',)\n",
      "('>75',)\n",
      "('<35',)\n",
      "[0, 0.10395, 0.1478, 0.248, 0.50025, 1]\n",
      "('35-49', 'LolwOutQuad', 'No')\n",
      "('35-49', 'LolwOutQuad', 'Invasive')\n",
      "('35-49', 'LolwOutQuad', 'Insitu')\n",
      "('35-49', 'UpOutQuad', 'No')\n",
      "('35-49', 'UpOutQuad', 'Invasive')\n",
      "('35-49', 'UpOutQuad', 'Insitu')\n",
      "('35-49', 'UpInQuad', 'No')\n",
      "('35-49', 'UpInQuad', 'Invasive')\n",
      "('35-49', 'UpInQuad', 'Insitu')\n",
      "('35-49', 'LowInQuad', 'No')\n",
      "('35-49', 'LowInQuad', 'Invasive')\n",
      "('35-49', 'LowInQuad', 'Insitu')\n",
      "('50-74', 'LolwOutQuad', 'No')\n",
      "('50-74', 'LolwOutQuad', 'Invasive')\n",
      "('50-74', 'LolwOutQuad', 'Insitu')\n",
      "('50-74', 'UpOutQuad', 'No')\n",
      "('50-74', 'UpOutQuad', 'Invasive')\n",
      "('50-74', 'UpOutQuad', 'Insitu')\n",
      "('50-74', 'UpInQuad', 'No')\n",
      "('50-74', 'UpInQuad', 'Invasive')\n",
      "('50-74', 'UpInQuad', 'Insitu')\n",
      "('50-74', 'LowInQuad', 'No')\n",
      "('50-74', 'LowInQuad', 'Invasive')\n",
      "('50-74', 'LowInQuad', 'Insitu')\n",
      "('>75', 'LolwOutQuad', 'No')\n",
      "('>75', 'LolwOutQuad', 'Invasive')\n",
      "('>75', 'LolwOutQuad', 'Insitu')\n",
      "('>75', 'UpOutQuad', 'No')\n",
      "('>75', 'UpOutQuad', 'Invasive')\n",
      "('>75', 'UpOutQuad', 'Insitu')\n",
      "('>75', 'UpInQuad', 'No')\n",
      "('>75', 'UpInQuad', 'Invasive')\n",
      "('>75', 'UpInQuad', 'Insitu')\n",
      "('>75', 'LowInQuad', 'No')\n",
      "('>75', 'LowInQuad', 'Invasive')\n",
      "('>75', 'LowInQuad', 'Insitu')\n",
      "('<35', 'LolwOutQuad', 'No')\n",
      "('<35', 'LolwOutQuad', 'Invasive')\n",
      "('<35', 'LolwOutQuad', 'Insitu')\n",
      "('<35', 'UpOutQuad', 'No')\n",
      "('<35', 'UpOutQuad', 'Invasive')\n",
      "('<35', 'UpOutQuad', 'Insitu')\n",
      "('<35', 'UpInQuad', 'No')\n",
      "('<35', 'UpInQuad', 'Invasive')\n",
      "('<35', 'UpInQuad', 'Insitu')\n",
      "('<35', 'LowInQuad', 'No')\n",
      "('<35', 'LowInQuad', 'Invasive')\n",
      "('<35', 'LowInQuad', 'Insitu')\n",
      "[0, 0.0056179775280898875, 0.00749063670411985, 0.015594541910331383, 0.017543859649122806, 0.020872865275142316, 0.023762376237623763, 0.0297029702970297, 0.03225806451612903, 0.09688013136288999, 0.0989159891598916, 0.10482594936708861, 0.12464985994397759, 0.14039408866995073, 0.14158576051779936, 0.14323607427055704, 0.1496031746031746, 0.15733333333333333, 0.1606012658227848, 0.161186848436247, 0.17313915857605178, 0.1856368563685637, 0.18591772151898733, 0.19691433211530654, 0.19887278582930756, 0.20133333333333334, 0.20159151193633953, 0.25442834138486314, 0.2549019607843137, 0.3011904761904762, 0.3032886723507917, 0.34522854851643947, 0.3548259493670886, 0.49358460304731355, 0.4997969955339017, 0.5403481012658228, 0.5466988727858293, 0.5492063492063493, 0.6204481792717087, 0.6413333333333333, 0.6534810126582279, 0.6551724137931034, 0.6852750809061489, 0.7154471544715447, 0.7627257799671593, 0.9465346534653465, 0.9468690702087287, 0.9668615984405458, 0.9868913857677902, 1]\n",
      "('No', 'No')\n",
      "('No', 'Yes')\n",
      "('Invasive', 'No')\n",
      "('Invasive', 'Yes')\n",
      "('Insitu', 'No')\n",
      "('Insitu', 'Yes')\n",
      "[0, 0.05193343516359836, 0.2963354474982382, 0.45289011221681136, 0.5471098877831887, 0.7036645525017619, 0.9480665648364016, 1]\n",
      "('No', 'No')\n",
      "('No', 'Yes')\n",
      "('Yes', 'No')\n",
      "('Yes', 'Yes')\n",
      "[0, 0.25592939878654164, 0.34957860021986076, 0.6504213997801392, 0.7440706012134584, 1]\n",
      "('No', 'No')\n",
      "('No', 'Yes')\n",
      "('Yes', 'No')\n",
      "('Yes', 'Yes')\n",
      "[0, 0.1497667991017447, 0.2550463072904298, 0.7449536927095701, 0.8502332008982553, 1]\n",
      "('No', 'No', 'Well-defined')\n",
      "('No', 'No', 'Ill-defined')\n",
      "('No', 'Yes', 'Well-defined')\n",
      "('No', 'Yes', 'Ill-defined')\n",
      "('Benign', 'No', 'Well-defined')\n",
      "('Benign', 'No', 'Ill-defined')\n",
      "('Benign', 'Yes', 'Well-defined')\n",
      "('Benign', 'Yes', 'Ill-defined')\n",
      "('Malign', 'No', 'Well-defined')\n",
      "('Malign', 'No', 'Ill-defined')\n",
      "('Malign', 'Yes', 'Well-defined')\n",
      "('Malign', 'Yes', 'Ill-defined')\n",
      "[0, 0.0, 0.0, 0.05555555555555555, 0.2064975522919448, 0.2523709167544784, 0.3572496263079223, 0.6427503736920778, 0.7476290832455216, 0.7935024477080552, 0.9444444444444444, 1.0, 1.0, 1]\n",
      "('No', 'No', 'No')\n",
      "('No', 'No', 'Yes')\n",
      "('No', 'Yes', 'No')\n",
      "('No', 'Yes', 'Yes')\n",
      "('Invasive', 'No', 'No')\n",
      "('Invasive', 'No', 'Yes')\n",
      "('Invasive', 'Yes', 'No')\n",
      "('Invasive', 'Yes', 'Yes')\n",
      "('Insitu', 'No', 'No')\n",
      "('Insitu', 'No', 'Yes')\n",
      "('Insitu', 'Yes', 'No')\n",
      "('Insitu', 'Yes', 'Yes')\n",
      "[0, 0.04918657854600915, 0.15345167652859962, 0.23127463863337713, 0.3355939619339313, 0.3359232175502742, 0.3662613981762918, 0.6337386018237082, 0.6640767824497258, 0.6644060380660687, 0.7687253613666228, 0.8465483234714004, 0.9508134214539908, 1]\n",
      "('No', 'No', 'No')\n",
      "('No', 'No', 'Yes')\n",
      "('No', 'Yes', 'No')\n",
      "('No', 'Yes', 'Yes')\n",
      "('Invasive', 'No', 'No')\n",
      "('Invasive', 'No', 'Yes')\n",
      "('Invasive', 'Yes', 'No')\n",
      "('Invasive', 'Yes', 'Yes')\n",
      "('Insitu', 'No', 'No')\n",
      "('Insitu', 'No', 'Yes')\n",
      "('Insitu', 'Yes', 'No')\n",
      "('Insitu', 'Yes', 'Yes')\n",
      "[0, 0.04867819013726487, 0.15660749506903354, 0.24375821287779237, 0.32750759878419455, 0.3463137169109604, 0.3560329067641682, 0.6439670932358318, 0.6536862830890396, 0.6724924012158054, 0.7562417871222076, 0.8433925049309665, 0.9513218098627352, 1]\n",
      "('No', 'No')\n",
      "('No', 'Yes')\n",
      "('Invasive', 'No')\n",
      "('Invasive', 'Yes')\n",
      "('Insitu', 'No')\n",
      "('Insitu', 'Yes')\n",
      "[0, 0.027976525444167538, 0.46919330933728565, 0.48731501057082455, 0.5126849894291755, 0.5308066906627144, 0.9720234745558325, 1]\n",
      "('No', 'no')\n",
      "('No', 'yes')\n",
      "('Invasive', 'no')\n",
      "('Invasive', 'yes')\n",
      "('Insitu', 'no')\n",
      "('Insitu', 'yes')\n",
      "[0, 0.0, 0.10374761803938175, 0.1434108527131783, 0.8565891472868217, 0.8962523819606183, 1.0, 1]\n",
      "('no', 'no')\n",
      "('no', 'yes')\n",
      "('yes', 'no')\n",
      "('yes', 'yes')\n",
      "[0, 0.0966796875, 0.1564655172413793, 0.8435344827586206, 0.9033203125, 1]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Recursively find child nodes such that nodes first in the ordering have no more unvisited children.\n",
    "def topologicalSortRec(G, v, ordering, visited):\n",
    "    \n",
    "    visited.append(v)\n",
    "    for child in G[v]:  \n",
    "        if child not in visited:\n",
    "            topologicalSortRec(G, child, ordering, visited)\n",
    "        \n",
    "    ordering.insert(0, v)\n",
    "\n",
    "#Find a topological ordering on the graph\n",
    "def topologicalSort(graph):\n",
    "    \n",
    "    ordering = []\n",
    "    visited = []\n",
    "    \n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            topologicalSortRec(graph, node, ordering, visited)\n",
    "            \n",
    "           \n",
    "    return ordering  # return the stack - ordering on the graph\n",
    "        \n",
    "\n",
    "def getSampleSpace(table, node):\n",
    "    \n",
    "    lst = list(table.items())\n",
    "    \n",
    "    space = list(lst[1])\n",
    "    space = list(space[1].items())\n",
    "    \n",
    "     \n",
    "    return space\n",
    "    \n",
    "\n",
    "def sampleValue(sampleSpace):\n",
    "    \n",
    "    rnd = random.random()\n",
    "    \n",
    "    lst = [0]\n",
    "    \n",
    "    for row in sampleSpace:\n",
    "        lst.append(row[1])\n",
    "        \n",
    "    lst.append(1)\n",
    "    lst.sort() \n",
    "    \n",
    "    prob = 0\n",
    "    # sampling correctly ?????\n",
    "    for index in range(1, len(lst)):\n",
    "        \n",
    "        if rnd >= lst[index-1] and rnd < lst[index]:\n",
    "            prob = lst[index]\n",
    "            if prob == 1:\n",
    "                prob = lst[index- 1]\n",
    "            break\n",
    "         \n",
    "    chosenVal = ''\n",
    "\n",
    "    for val in sampleSpace:\n",
    "        if val[1] == prob:\n",
    "            chosenVal = val[0]\n",
    "       \n",
    "                   \n",
    "    return chosenVal\n",
    "    \n",
    "        \n",
    "    \n",
    "def sample(graph, prob_tables):\n",
    "    \n",
    "    ordering = topologicalSort(graph)\n",
    "    samples = {}\n",
    "    \n",
    "    for node in ordering:\n",
    "        sampleSpace = getSampleSpace(prob_tables[node], node)\n",
    "        \n",
    "        val = sampleValue(sampleSpace)\n",
    "        samples[node] = val     \n",
    "\n",
    "    return samples\n",
    "\n",
    "#for x in range(1000):\n",
    "s = sample(graph, prob_tables)\n",
    "    #print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
