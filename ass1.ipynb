{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get data from file, learn parameters\n",
    "from collections import OrderedDict as odict\n",
    "import pandas as pd\n",
    "from itertools import product, combinations\n",
    "import numpy as np\n",
    "from tabulate import tabulate\n",
    "\n",
    "\n",
    "#================= Code from Week 3 Tutorial ====================================\n",
    "\n",
    "\n",
    "def allEqualThisIndex(dict_of_arrays, **fixed_vars):\n",
    "    \"\"\"\n",
    "    Helper function to create a boolean index vector into a tabular data structure,\n",
    "    such that we return True only for rows of the table where, e.g.\n",
    "    column_a=fixed_vars['column_a'] and column_b=fixed_vars['column_b'].\n",
    "    \n",
    "    This is a simple task, but it's not *quite* obvious\n",
    "    for various obscure technical reasons.\n",
    "    \n",
    "    It is perhaps best explained by an example.\n",
    "    \n",
    "    >>> all_equal_this_index(\n",
    "    ...    {'X': [1, 1, 0], Y: [1, 0, 1]},\n",
    "    ...    X=1,\n",
    "    ...    Y=1\n",
    "    ... )\n",
    "    [True, False, False]\n",
    "    \"\"\"\n",
    "    # base index is a boolean vector, everywhere true\n",
    "    first_array = dict_of_arrays[list(dict_of_arrays.keys())[0]]\n",
    "    index = np.ones_like(first_array, dtype=np.bool_)\n",
    "    for var_name, var_val in fixed_vars.items():\n",
    "        index = index & (np.asarray(dict_of_arrays[var_name])==var_val)\n",
    "    return index\n",
    "\n",
    "\n",
    "\n",
    "def printFactor(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, a factor to print on screen\n",
    "    \"\"\"\n",
    "    # Create a empty list that we will fill in with the probability table entries\n",
    "    table = list()\n",
    "    \n",
    "    # Iterate over all keys and probability values in the table\n",
    "    for key, item in f['table'].items():\n",
    "        # Convert the tuple to a list to be able to manipulate it\n",
    "        k = list(key)\n",
    "        # Append the probability value to the list with key values\n",
    "        k.append(item)\n",
    "        # Append an entire row to the table\n",
    "        table.append(k)\n",
    "    # dom is used as table header. We need it converted to list\n",
    "    dom = list(f['dom'])\n",
    "    # Append a 'Pr' to indicate the probabity column\n",
    "    dom.append('Pr')\n",
    "    print(tabulate(table,headers=dom,tablefmt='orgtbl'))\n",
    "\n",
    "def transposeGraph(G):\n",
    "    GT = dict((v, []) for v in G)\n",
    "    for v in G:\n",
    "        for w in G[v]:\n",
    "            if w in GT:\n",
    "                GT[w].append(v)\n",
    "            else:\n",
    "                GT[w] = [v]\n",
    "    return GT\n",
    "\n",
    "\n",
    "# From Week 2 Tutorial\n",
    "def estProbTable(data, var_name, parent_names, outcomeSpace):\n",
    "    \"\"\"\n",
    "    Calculate a dictionary probability table by ML given\n",
    "    `data`, a dictionary or dataframe of observations\n",
    "    `var_name`, the column of the data to be used for the conditioned variable and\n",
    "    `var_outcomes`, a tuple of possible outcomes for the conditiona varible and\n",
    "    `parent_names`, a tuple of columns to be used for the parents and\n",
    "    `parent_outcomes` a tuple of all possible parent outcomes \n",
    "    Return a dictionary containing an estimated conditional probability table.\n",
    "    \"\"\"    \n",
    "    var_outcomes = outcomeSpace[var_name]\n",
    "    parent_outcomes = [outcomeSpace[var] for var in (parent_names)]\n",
    "    # cartesian product to generate a table of all possible outcomes\n",
    "    all_parent_combinations = product(*parent_outcomes)\n",
    "\n",
    "    prob_table = odict()\n",
    "    \n",
    "    for i, parent_combination in enumerate(all_parent_combinations):\n",
    "        cond_array = []\n",
    "        parent_vars = dict(zip(parent_names, parent_combination))\n",
    "        parent_index = allEqualThisIndex(data, **parent_vars)\n",
    "        for var_outcome in var_outcomes:\n",
    "            var_index = (np.asarray(data[var_name])==var_outcome)\n",
    "            prob_table[tuple(list(parent_combination)+[var_outcome])] = (var_index & parent_index).sum()/parent_index.sum() \n",
    "           \n",
    "    return {'dom': tuple(list(parent_names)+[var_name]), 'table': prob_table}\n",
    "\n",
    "#==========================================================\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimated P(b)=Shape\n",
      "| Mass   | Shape     |        Pr |\n",
      "|--------+-----------+-----------|\n",
      "| No     | Other     | 1         |\n",
      "| No     | Oval      | 0         |\n",
      "| No     | Round     | 0         |\n",
      "| No     | Irregular | 0         |\n",
      "| Benign | Other     | 0.0553152 |\n",
      "| Benign | Oval      | 0.239184  |\n",
      "| Benign | Round     | 0.652967  |\n",
      "| Benign | Irregular | 0.052534  |\n",
      "| Malign | Other     | 0         |\n",
      "| Malign | Oval      | 0.153493  |\n",
      "| Malign | Round     | 0.104907  |\n",
      "| Malign | Irregular | 0.7416    |\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "graph = {\n",
    "    'LymphNodes': [],\n",
    "    'Metastasis': ['LymphNodes'],\n",
    "    'BC': ['Metastasis','MC', 'SkinRetract', 'NippleDischarge', 'AD'],\n",
    "    'MC': [],\n",
    "    'Age': ['BC'],\n",
    "    'Location': ['BC'],\n",
    "    'BreastDensity': ['Mass'],\n",
    "    'Mass': ['Size', 'Shape', 'Margin'],\n",
    "    'Size': [],\n",
    "    'Shape': [],\n",
    "    'Margin': [],\n",
    "    'Spiculation': ['Margin'],\n",
    "    'FibrTissueDev': ['Spiculation', 'NippleDischarge', 'SkinRetract'],\n",
    "    'NippleDischarge': [],\n",
    "    'SkinRetract' : [],\n",
    "    'AD' : ['FibrTissueDev'],\n",
    "}\n",
    "\n",
    "graphT = transposeGraph(graph)\n",
    "\n",
    "\"\"\"\n",
    "Read the data, and return an outcomeSpace dictionary with\n",
    "all of the different nodes, and their domains\n",
    "\"\"\"\n",
    "def getOutcomeSpace(data):\n",
    "    \n",
    "    nodes = []\n",
    "    outcomes = []\n",
    "    \n",
    "    for x in data:\n",
    "        nodes.append(x)\n",
    "        count = 0\n",
    "        diffList = []\n",
    "        for val in data[x]:            \n",
    "            if val not in diffList:\n",
    "                count += 1\n",
    "                diffList.append(val)        \n",
    "        outcomes.append(diffList)\n",
    "        \n",
    "    outcomeSpace = {}\n",
    "    for i in range(len(nodes)):\n",
    "        outcomeSpace[nodes[i]] = tuple(outcomes[i])\n",
    "    \n",
    "   \n",
    "    return dict(outcomeSpace)\n",
    "\n",
    "def learn_bayes_net(graph, file, outcomeSpace, prob_tables):\n",
    "    \n",
    "\n",
    "    with open(file) as h:\n",
    "        data = pd.read_csv(h)\n",
    "\n",
    "    # possible outcomes, by variable\n",
    "    outcomeSpace = getOutcomeSpace(data)\n",
    "      \n",
    "\n",
    "    prob_tables = odict()\n",
    "    for node, parents in graphT.items():    \n",
    "        prob_tables[node] = estProbTable(         # Estimate the probability for a single table. 1 line\n",
    "            data,\n",
    "            node,\n",
    "            parents,\n",
    "            outcomeSpace)\n",
    "\n",
    "    ##############################\n",
    "    # Test code\n",
    "    ##############################\n",
    "    print('estimated P(b)=Shape')\n",
    "    printFactor(prob_tables['Shape'])\n",
    "    print()\n",
    "\n",
    "  \n",
    "    return outcomeSpace, prob_tables\n",
    "\n",
    "    \n",
    "prob_tables = []\n",
    "outcomeSpace = []\n",
    "\n",
    "outcomeSpace, prob_tables = learn_bayes_net(graph, 'bc 2.csv', outcomeSpace, prob_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Recursively find child nodes such that nodes first in the ordering have no more unvisited children.\n",
    "def topologicalSortRec(G, v, ordering, visited):\n",
    "    \n",
    "    visited.append(v)\n",
    "    for child in G[v]:  \n",
    "        if child not in visited:\n",
    "            topologicalSortRec(G, child, ordering, visited)\n",
    "        \n",
    "    ordering.insert(0, v)\n",
    "\n",
    "#Find a topological ordering on the graph\n",
    "def topologicalSort(graph):\n",
    "    \n",
    "    ordering = []\n",
    "    visited = []\n",
    "    \n",
    "    for node in graph:\n",
    "        if node not in visited:\n",
    "            topologicalSortRec(graph, node, ordering, visited)\n",
    "            \n",
    "          \n",
    "    return ordering  # return the stack - ordering on the graph\n",
    "        \n",
    "#Returns a table with the subset of entries to consider for sampling - based on evidence\n",
    "def getSampleSpace(table, samples, node):\n",
    "    \n",
    "    keys = list(table['dom'])\n",
    "    \n",
    "    nodeIndex = keys.index(node)\n",
    "    \n",
    "    observed = []\n",
    "    indexes = {}\n",
    "    \n",
    "    for i in samples:\n",
    "        if i in keys:\n",
    "            observed.append(i)\n",
    "            indexes[keys.index(i)] = i\n",
    "        \n",
    "   \n",
    "    space = []\n",
    "    \n",
    "    listTable = list(table['table'].items())\n",
    "    \n",
    "    #Iterate through the table values, and take the ones with the correct data\n",
    "    for example in listTable:\n",
    "        nodes = list(example[0])\n",
    "        add = True\n",
    "        for i in indexes.keys():        \n",
    "            if nodes[i] != samples[indexes[i]]:\n",
    "                add = False\n",
    "                break\n",
    "        #Add the row from the table with the correctly observed data\n",
    "        if add == True:\n",
    "            space.append(example)\n",
    "            \n",
    "      \n",
    "    return space, nodeIndex\n",
    "    \n",
    "# Use a random number to generate a value from the outcomeSpace of var given the Sample Space probabilities\n",
    "def sampleValue(sampleSpace, nodeIndex):\n",
    "    \n",
    "    \n",
    "    rnd = random.random()\n",
    "    \n",
    "    lst = []\n",
    "    names = {}\n",
    "    for row in sampleSpace:\n",
    "        lst.append(row[1])\n",
    "        names[str(row[1])] = list(row[0])[nodeIndex]\n",
    "           \n",
    "    lst.sort()    \n",
    "\n",
    "    lst.insert(0, 0)\n",
    "   \n",
    "    #Split up the probabilities into 'regions' for the rnd to fall into    \n",
    "    regions = []\n",
    "    sumVal = 0\n",
    "    for i in range(1, len(lst)):\n",
    "        sumVal += lst[i - 1]\n",
    "        regions.append(lst[i] + sumVal)        \n",
    "    \n",
    "    lst.pop(0)\n",
    "        \n",
    "    for indx in range(len(regions)):\n",
    "        if rnd < regions[indx]:\n",
    "            chosen = indx\n",
    "            break\n",
    "   \n",
    "    chosenVal = names[str(lst[chosen])]     \n",
    "          \n",
    "    return chosenVal\n",
    "    \n",
    "#Sample from the graph in topological order\n",
    "def sample(graph, prob_tables):\n",
    "    \n",
    "    ordering = topologicalSort(graph)\n",
    "    samples = {}\n",
    " \n",
    "    for node in ordering:\n",
    "        sampleSpace, nodeIndex = getSampleSpace(prob_tables[node], samples, node)\n",
    "\n",
    "        val = sampleValue(sampleSpace, nodeIndex)\n",
    "        samples[node] = val     \n",
    "\n",
    "    return samples\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 721,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| BC       |       Pr |\n",
      "|----------+----------|\n",
      "| No       | 0.493585 |\n",
      "| Invasive | 0.345229 |\n",
      "| Insitu   | 0.161187 |\n"
     ]
    }
   ],
   "source": [
    "# ================== Code from wk  3 tutorial ======================\n",
    "def normalize(f):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be normalized.\n",
    "    \n",
    "    Returns a new factor f' as a copy of f with entries that sum up to 1\n",
    "    \"\"\" \n",
    "    table = list()\n",
    "    sum = 0\n",
    "    for k, p in f['table'].items():\n",
    "        sum = sum + p\n",
    "    for k, p in f['table'].items():\n",
    "        table.append((k, p/sum))\n",
    "    return {'dom': f['dom'], 'table': odict(table)}\n",
    "\n",
    "def prob(factor, *entry):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `factor`, a dictionary of domain and probability values,\n",
    "    `entry`, a list of values, one for each variable in the same order as specified in the factor domain.\n",
    "    \n",
    "    Returns p(entry)\n",
    "    \"\"\"\n",
    "\n",
    "    return factor['table'][entry]     # insert your code here, 1 line    \n",
    "\n",
    "def join(f1, f2, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f1`, first factor to be joined.\n",
    "    `f2`, second factor to be joined.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor with a join of f1 and f2\n",
    "    \"\"\"\n",
    "    \n",
    "    # First, we need to determine the domain of the new factor. It will be union of the domain in f1 and f2\n",
    "    # But it is important to eliminate the repetitions\n",
    "    common_vars = list(f1['dom']) + list(set(f2['dom']) - set(f1['dom']))\n",
    "    \n",
    "    # We will build a table from scratch, starting with an empty list. Later on, we will transform the list into a odict\n",
    "    table = list()\n",
    "    \n",
    "    # Here is where the magic happens. The product iterator will generate all combinations of varible values \n",
    "    # as specified in outcomeSpace. Therefore, it will naturally respect observed values\n",
    "    for entries in product(*[outcomeSpace[node] for node in common_vars]):\n",
    "        \n",
    "        # We need to map the entries to the domain of the factors f1 and f2\n",
    "        entryDict = dict(zip(common_vars, entries))\n",
    "        f1_entry = (entryDict[var] for var in f1['dom'])\n",
    "        f2_entry = (entryDict[var] for var in f2['dom'])\n",
    "        \n",
    "        # Insert your code here\n",
    "        p1 = prob(f1, *f1_entry)           # Use the fuction prob to calculate the probability in factor f1 for entry f1_entry \n",
    "        p2 = prob(f2, *f2_entry)           # Use the fuction prob to calculate the probability in factor f2 for entry f2_entry \n",
    "        \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, p1 * p2))\n",
    "    return {'dom': tuple(common_vars), 'table': odict(table)}\n",
    "\n",
    "\n",
    "\n",
    "def p_joint(outcomeSpace, cond_tables, nodeList):\n",
    "            \n",
    "   \n",
    "    if len(nodeList) < 2:\n",
    "        return cond_tables\n",
    "    \n",
    "    \"\"\"\n",
    "    argument \n",
    "    `outcomeSpace`, dictionary with domain of each variable\n",
    "    `cond_tables`, conditional probability distributions estimated from data\n",
    "    \n",
    "    Returns a new factor with full joint distribution\n",
    "    \"\"\"\n",
    "    \n",
    "    p = join(cond_tables[nodeList[0]],  cond_tables[nodeList[1]], outcomeSpace)\n",
    "    for n in range(2, len(nodeList)):\n",
    "        p = join(p, cond_tables[nodeList[n]], outcomeSpace)\n",
    "   \n",
    "    return p\n",
    "\n",
    "\n",
    "def marginalize(f, var, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `f`, factor to be marginalized.\n",
    "    `var`, variable to be summed out.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns a new factor f' with dom(f') = dom(f) - {var}\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Let's make a copy of f domain and convert it to a list. We need a list to be able to modify its elements\n",
    "    new_dom = list(f['dom'])\n",
    "  \n",
    "       \n",
    "    #########################\n",
    "    # Insert your code here #\n",
    "    #########################\n",
    "    new_dom.remove(var)   \n",
    "    # Remove var from the list new_dom by calling the method remove(). 1 line\n",
    "    table = list()                 # Create an empty list for table. We will fill in table from scratch. 1 line\n",
    "    for entries in product(*[outcomeSpace[node] for node in new_dom]):\n",
    "        s = 0;                     # Initialize the summation variable s. 1 line\n",
    "\n",
    "        # We need to iterate over all possible outcomes of the variable var\n",
    "        for val in outcomeSpace[var]:\n",
    "            # To modify the tuple entries, we will need to convert it to a list\n",
    "            entriesList = list(entries)\n",
    "            # We need to insert the value of var in the right position in entriesList\n",
    "            entriesList.insert(f['dom'].index(var), val)\n",
    "            \n",
    "\n",
    "            #########################\n",
    "            # Insert your code here #\n",
    "            #########################\n",
    "            \n",
    "            p = prob(f, *tuple(entriesList))     # Calculate the probability of factor f for entriesList. 1 line\n",
    "            s = s + p                            # Sum over all values of var by accumulating the sum in s. 1 line\n",
    "            \n",
    "        # Create a new table entry with the multiplication of p1 and p2\n",
    "        table.append((entries, s))\n",
    "    return {'dom': tuple(new_dom), 'table': odict(table)}\n",
    "\n",
    "\n",
    "def evidence(var, e, outcomeSpace):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `var`, a valid variable identifier.\n",
    "    `e`, the observed value for var.\n",
    "    `outcomeSpace`, dictionary with the domain of each variable\n",
    "    \n",
    "    Returns dictionary with a copy of outcomeSpace with var = e\n",
    "    \"\"\"    \n",
    "    newOutcomeSpace = outcomeSpace.copy()      # Make a copy of outcomeSpace with a copy to method copy(). 1 line\n",
    "    newOutcomeSpace[var] = (e,)                # Replace the domain of variable var with a tuple with a single element e. 1 line\n",
    "    return newOutcomeSpace\n",
    "\n",
    "def query(p, outcomeSpace, q_vars, q_evi):\n",
    "    \"\"\"\n",
    "    argument \n",
    "    `p`, probability table to query.\n",
    "    `outcomeSpace`, dictionary will variable domains\n",
    "    `q_vars`, list of variables in query head\n",
    "    `q_evi`, dictionary of evidence in the form of variables names and values\n",
    "    \n",
    "    Returns a new factor NORMALIZED factor will all hidden variables eliminated as evidence set as in q_evi\n",
    "    \"\"\"     \n",
    "    \n",
    "    # Let's make a copy of these structures, since we will reuse the variable names\n",
    "    pm = p.copy()\n",
    "    outSpace = outcomeSpace.copy()\n",
    "    \n",
    "    # First, we set the evidence \n",
    "    for var_evi, e in q_evi.items():\n",
    "        outSpace = evidence(var_evi, e, outSpace)\n",
    "    \n",
    "    # Second, we eliminate hidden variables NOT in the query\n",
    "    for var in outSpace:\n",
    "        if not var in q_vars:            \n",
    "            pm = marginalize(pm, var, outSpace)\n",
    "            \n",
    "    return normalize(pm)\n",
    "\n",
    "#=========================================================================\n",
    "\n",
    "queryNodes = list(outcomeSpace.keys())\n",
    "p = p_joint(outcomeSpace, prob_tables, queryNodes)\n",
    "#########################\n",
    "# Test code\n",
    "#########################\n",
    "printFactor(query(p, outcomeSpace,['BC'], {'Age':'50-74', 'Location':'UpInQuad'}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| BC       | LymphNodes   |         Pr |\n",
      "|----------+--------------+------------|\n",
      "| No       | no           | 0.731706   |\n",
      "| No       | yes          | 0.0783123  |\n",
      "| Invasive | no           | 0.0288116  |\n",
      "| Invasive | yes          | 0.00308362 |\n",
      "| Insitu   | no           | 0.142803   |\n",
      "| Insitu   | yes          | 0.0152838  |\n"
     ]
    }
   ],
   "source": [
    "#Different Queries for the network\n",
    "\n",
    "#Bayesian Network\n",
    "printFactor(query(p, outcomeSpace,['LymphNodes', 'BC'], {'Metastasis' : 'no'}))\n",
    "#more queries....\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 716,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'No': 89, 'Invasive': 28, 'Insitu': 32}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 716,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def querySample(samples, var, var_evi, outcomeSpace):\n",
    "    \n",
    "    if len(samples) == 0:\n",
    "        return\n",
    "    \n",
    "    #Initalise frequency dictionary\n",
    "    frequencies = {}   \n",
    "    for k in samples[0]:\n",
    "        frequencies[k] = {}\n",
    "        for o in outcomeSpace[k]:\n",
    "            frequencies[k][o] = 0\n",
    "\n",
    "    for s in samples:\n",
    "        discard = False\n",
    "        for key, it in s.items():\n",
    "            if key in var_evi:\n",
    "                if var_evi[key] != it:                   \n",
    "                    discard = True\n",
    "                    break\n",
    "                    \n",
    "                \n",
    "        #Discard sample if disagrees with evidence          \n",
    "        if discard == True:\n",
    "            continue\n",
    "            \n",
    "        #Update variable frequencies\n",
    "        for key in var:\n",
    "            frequencies[key][s[key]] += 1\n",
    "    print(frequencies[var[0]])\n",
    "     \n",
    "    return 0\n",
    "\n",
    "\n",
    "generatedSamples = []\n",
    "\n",
    "# Generate 1000 Samples from forward sampling on the network\n",
    "for x in range(1000):\n",
    "    s = sample(graph, prob_tables)\n",
    "    generatedSamples.append(s)\n",
    "    \n",
    "    \n",
    "#Sample queries (same as bayesian)\n",
    "querySample(generatedSamples, ['BC'], {'Mass':'No', 'Age':'35-49'}, outcomeSpace)\n",
    "#more queries...\n",
    "\n",
    "\n",
    "#Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
